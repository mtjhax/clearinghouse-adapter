require 'csv'

class ExportProcessor < Processor::Export::Base
  # This is the default processor. You can override it in your own
  # processor files
  
  def process!(updated_trips, export_dir)
    raise "Export folder #{export_dir} does not exist" if Dir[export_dir].empty?

    # TODO
    export_dir = options[:export][:export_folder]
    raise "Export folder not configured, will not export new changes detected on the Clearinghouse" if export_dir.blank?


              
    trip_updates = [], claim_updates = [], comment_updates = [], result_updates = []
    
    updated_trips.each do |trip|
      trip_data = trip.data.with_indifferent_access
      
      if trip_data[:update_type] == 'modified'
        # pluck the modifications to claims, comments, and results out of the trip to report them separately
        claims = trip_diff.delete(:trip_claims) || []
        comments = trip_diff.delete(:trip_ticket_comments) || []
        result = trip_diff.delete(:trip_result) || []

        # save results for export
        # make sure the trip_diff with the claims, comments, and results removed is not blank or just an ID
        clean_trip_diff = clean_diff(trip_diff)
        unless clean_trip_diff.blank? || clean_trip_diff.keys == ['id']
          trip_updates << { update_type: 'modified' }.merge(clean_trip_diff)
        end
        claims.each { |claim_diff| record_changes(claim_diff, claim_updates) }
        comments.each { |comment_diff| record_changes(comment_diff, comment_updates) }
        record_changes(result, result_updates) if result.present?
      else
        # pluck the modifications to claims, comments, and results out of the trip to report them separately
        claims = trip.delete(:trip_claims)
        comments = trip.delete(:trip_ticket_comments)
        result = trip.delete(:trip_result)

        # save results for export
        trip_updates << { update_type: 'new_record' }.merge(trip) unless trip.blank?
        result_updates << { update_type: 'new_record' }.merge(result) if result.present?
        claims.each { |c| claim_updates << { update_type: 'new_record' }.merge(c) if c.present? }
        comments.each { |c| comment_updates << { update_type: 'new_record' }.merge(c) if c.present? }
      end    
    
    
    # flatten nested structures in the updated trips
    flattened_trips, flattened_claims, flattened_comments, flattened_results = [[], [], [], []]
    trip_updates.each { |x| flattened_trips << flatten_hash(x) }
    claim_updates.each { |x| flattened_claims << flatten_hash(x) }
    comment_updates.each { |x| flattened_comments << flatten_hash(x) }
    result_updates.each { |x| flattened_results << flatten_hash(x) }

    # create combined lists of keys since each change set can include different updated columns
    trip_keys, claim_keys, comment_keys, result_keys = [[], [], [], []]
    flattened_trips.each { |x| trip_keys |= x.stringify_keys.keys }
    flattened_claims.each { |x| claim_keys |= x.stringify_keys.keys }
    flattened_comments.each { |x| comment_keys |= x.stringify_keys.keys }
    flattened_results.each { |x| result_keys |= x.stringify_keys.keys }

    # create file names for exports
    timestamp = timestamp_string
    trip_file = File.join(export_dir, "trip_tickets.#{timestamp}.csv")
    claim_file = File.join(export_dir, "trip_claims.#{timestamp}.csv")
    comment_file = File.join(export_dir, "trip_ticket_comments.#{timestamp}.csv")
    result_file = File.join(export_dir, "trip_results.#{timestamp}.csv")

    export_csv(trip_file, trip_keys, flattened_trips)
    export_csv(claim_file, claim_keys, flattened_claims)
    export_csv(comment_file, comment_keys, flattened_comments)
    export_csv(result_file, result_keys, flattened_results)
  end
  
  private
  
  def export_csv(filename, headers, data)
    if data.present?
      CSV.open(filename, 'wb', headers: headers, write_headers: true) do |csv|
        data.each {|result| csv << headers.map { |key| result[key] }}
      end
    end
  end
  
  # flatten hash structure, changing keys of nested objects to
  # parentkey_nestedkey arrays of sub-objects will be ignored
  # TODO hashes should be converted to an array 
  def flatten_hash(hash, prepend_name = nil)
    new_hash = {}
    hash.each do |key, value|
      new_key = [prepend_name, key.to_s].compact.join('_')
      case value
        when Hash
          new_hash.merge!(flatten_hash(value, new_key))
        when Array
          hash_array = value.index{|x| x.is_a?(Hash) }.present?
          new_hash[new_key] = value unless hash_array
        else
          new_hash[new_key] = value
      end
    end
    new_hash
  end
end